{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done defining functions...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "# from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from   torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from pytorchtools import EarlyStopping\n",
    "# from utils import Logger\n",
    "from torchsummary import summary\n",
    "\n",
    "import MMD as mmd\n",
    "import phate\n",
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "import scprep\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import r2_score\n",
    "from numpy import linalg as LA\n",
    "phate_op = phate.PHATE()\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import sample \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from itertools import islice\n",
    "seaborn.set_context(context=\"talk\")\n",
    "import math, copy, time\n",
    "import sys\n",
    "\n",
    "# class DiscriminatorNet(nn.Module):\n",
    "#     \"\"\"\n",
    "#     A three hidden-layer discriminative neural network\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         super(DiscriminatorNet, self).__init__()\n",
    "#         n_features = 512\n",
    "#         n_out = 1\n",
    "        \n",
    "#         self.hidden0 = nn.Sequential( \n",
    "#             nn.Linear(n_features, 100),\n",
    "#             nn.LeakyReLU(0.2)\n",
    "#         )\n",
    "#         self.hidden1 = nn.Sequential(\n",
    "#             nn.Linear(100, 100),\n",
    "#             nn.LeakyReLU(0.2)\n",
    "#         )\n",
    "#         self.hidden2 = nn.Sequential(\n",
    "#             nn.Linear(100, 100),\n",
    "#             nn.LeakyReLU(0.2)\n",
    "#         )\n",
    "#         self.out = nn.Sequential(\n",
    "#             torch.nn.Linear(100, n_out),\n",
    "#             torch.nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.hidden0(x)\n",
    "#         x = self.hidden1(x)\n",
    "#         x = self.hidden2(x)\n",
    "#         x = self.out(x)\n",
    "#         return x\n",
    "\n",
    "# class GeneratorNet(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     A three hidden-layer generative neural network\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         super(GeneratorNet, self).__init__()\n",
    "#         n_features = n_z\n",
    "#         n_out = 784\n",
    "        \n",
    "#         self.hidden0 = nn.Sequential(\n",
    "#             nn.Linear(n_features, 100),\n",
    "#             nn.LeakyReLU(0.2)\n",
    "#         )\n",
    "#         self.hidden1 = nn.Sequential(            \n",
    "#             nn.Linear(100, 100),\n",
    "#             nn.LeakyReLU(0.2)\n",
    "#         )\n",
    "#         self.hidden2 = nn.Sequential(\n",
    "#             nn.Linear(100, 100),\n",
    "#             nn.LeakyReLU(0.2)\n",
    "#         )\n",
    "        \n",
    "#         self.out = nn.Sequential(\n",
    "#             nn.Linear(100, n_out),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.hidden0(x)\n",
    "#         x = self.hidden1(x)\n",
    "#         x = self.hidden2(x)\n",
    "#         x = self.out(x)\n",
    "#         return x\n",
    "\n",
    "def images_to_vectors(images):\n",
    "    return images.view(images.size(0), 784)\n",
    "\n",
    "def vectors_to_images(vectors):\n",
    "    return vectors.view(vectors.size(0), 1, 28, 28)\n",
    "\n",
    "def noise(size):\n",
    "    '''\n",
    "    Generates a 1-d vector of gaussian sampled random values\n",
    "    '''\n",
    "    n = Variable(torch.randn(size, n_z))\n",
    "    return n\n",
    "\n",
    "# def train_discriminator(optimizer, french_data, english_data):\n",
    "#     # Reset gradients\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # Train on french data\n",
    "#     loss_discriminator = 0\n",
    "#     for j in range(1, french_data.size(0)):\n",
    "#         # print(\"Target:\", end=\"\\t\")\n",
    "#         # for k in range(1, english_data.size(1)): #Maximum sentence length in this batch\n",
    "#         #     sym = TGT.vocab.itos[english_data[j,k]] #Translating indexes to words of the first english sentence in this batch.\n",
    "#         #     if sym == \"</s>\": break\n",
    "#         #     print(\"(j={},k={}) {}\".format(j,k,sym))\n",
    "#         # print()\n",
    "#         # print(\"Source:\", end=\"\\t\")\n",
    "#         # for k in range(1, french_data.size(1)):\n",
    "#         #     sym = SRC.vocab.itos[french_data[j,k]] #Translating indexes to words of the first english sentence in this batch.\n",
    "#         #     if sym == \"</s>\": break\n",
    "#         #     print(\"(j={},k={}) {}\".format(j,k,sym))\n",
    "#         # print()\n",
    "\n",
    "#         french_data2 = french_data[j,french_data[j,:]!=1] #1=<blank>\n",
    "#         english_data2 = english_data[j,english_data[j,:]>3] #1=<blank>, 2=<s>, 3=</s>\n",
    "#         embed_src = model.src_embed[0].lut(french_data2.to(device)).cpu().detach()\n",
    "#         embed_tgt = model.tgt_embed[0].lut(english_data2.to(device)).cpu().detach()\n",
    "\n",
    "#         prediction_french = discriminator(embed_src)\n",
    "#         prediction_english = discriminator(embed_tgt)\n",
    "#         # print(\"prediction_french.size(): {}\".format(prediction_french.size()))\n",
    "#         # print(\"embed_src: {}\".format(embed_src))\n",
    "#         # print(\"embed_src.size(): {}\".format(embed_src.size()))\n",
    "#         # print(\"prediction_english.size(): {}\".format(prediction_english.size()))\n",
    "#         # print(\"embed_tgt: {}\".format(embed_tgt))\n",
    "#         # print(\"embed_tgt.size(): {}\".format(embed_tgt.size()))\n",
    "#         # print(\"french_data.squeeze().size(0)): {}\".format(french_data.squeeze().size(0)))\n",
    "        \n",
    "#         # Calculate error and backpropagate\n",
    "#         loss_discriminator += -(torch.mean(prediction_french) - torch.mean(prediction_english))**2\n",
    "#     loss_discriminator = (loss_discriminator/french_data.size(0))*weight_loss_discriminator\n",
    "\n",
    "#     loss_discriminator.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     return loss_discriminator, torch.mean(prediction_french), torch.mean(prediction_english)\n",
    "\n",
    "def french_data_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    # if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n",
    "\n",
    "def english_data_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    # if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n",
    "\n",
    "def plot_embeddings(path_save, string_name, epoch):\n",
    "    \n",
    "    #check it folder exists\n",
    "    directory = os.path.join(path_save,string_name)\n",
    "    if not os.path.exists(directory):\n",
    "        print(\"creating {}\".format(directory))\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    n_samples = 7000\n",
    "\n",
    "    sent_tgt = TGT.vocab.itos\n",
    "    sent_tgt_idx = torch.LongTensor([[TGT.vocab.stoi[w] for w in sent_tgt]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "    sent_tgt_idx = Variable(sent_tgt_idx)\n",
    "    sent_src = SRC.vocab.itos\n",
    "    sent_src_idx = torch.LongTensor([[SRC.vocab.stoi[w] for w in sent_src]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "    sent_src_idx = Variable(sent_src_idx)\n",
    "    print(sent_src_idx.size())\n",
    "    # print(sent_src_idx)\n",
    "\n",
    "    out_emb1 = model.tgt_embed[0].lut\n",
    "    sent_tgt_idx = out_emb1(sent_tgt_idx.to(device))\n",
    "\n",
    "    out_emb2 = model.src_embed[0].lut\n",
    "    sent_src_idx = out_emb2(sent_src_idx.to(device))\n",
    "    sent_tgt_idx = sent_tgt_idx.squeeze()\n",
    "    sent_src_idx = sent_src_idx.squeeze()\n",
    "    sent_idx = torch.cat((sent_tgt_idx[:n_samples], sent_src_idx[:n_samples]),0)\n",
    "    sent = sent_tgt[:n_samples] + sent_src[:n_samples]\n",
    "\n",
    "    # Raw embedding\n",
    "    temp=sent_tgt_idx[:n_samples].cpu().detach().numpy()\n",
    "    temp1=sent_src_idx[:n_samples].cpu().detach().numpy()\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(20, 20), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    axs[0, 0].scatter(temp[:n_samples-1,0], temp[:n_samples-1,1], s=10, alpha=0.5)\n",
    "    axs[0, 0].scatter(temp1[:n_samples-1,0], temp1[:n_samples-1,1], s=10, alpha=0.5)\n",
    "    axs[0, 0].set_title('[0,1]')\n",
    "    axs[0, 1].scatter(temp[:n_samples-1,0], temp[:n_samples-1,2], s=10, alpha=0.5)\n",
    "    axs[0, 1].scatter(temp1[:n_samples-1,0], temp1[:n_samples-1,2], s=10, alpha=0.5)\n",
    "    axs[0, 1].set_title('[0,2]')\n",
    "    axs[0, 2].scatter(temp[:n_samples-1,0], temp[:n_samples-1,3], s=10, alpha=0.5)\n",
    "    axs[0, 2].scatter(temp1[:n_samples-1,0], temp1[:n_samples-1,3], s=10, alpha=0.5)\n",
    "    axs[0, 2].set_title('[0,3]')\n",
    "    axs[1, 0].scatter(temp[:n_samples-1,1], temp[:n_samples-1,2], s=10, alpha=0.5)\n",
    "    axs[1, 0].scatter(temp1[:n_samples-1,1], temp1[:n_samples-1,2], s=10, alpha=0.5)\n",
    "    axs[1, 0].set_title('[1,2]')\n",
    "    axs[1, 1].scatter(temp[:n_samples-1,1], temp[:n_samples-1,3], s=10, alpha=0.5)\n",
    "    axs[1, 1].scatter(temp1[:n_samples-1,1], temp1[:n_samples-1,3], s=10, alpha=0.5)\n",
    "    axs[1, 1].set_title('[1,3]')\n",
    "    axs[1, 2].scatter(temp[:n_samples-1,1], temp[:n_samples-1,4], s=10, alpha=0.5)\n",
    "    axs[1, 2].scatter(temp1[:n_samples-1,1], temp1[:n_samples-1,4], s=10, alpha=0.5)\n",
    "    axs[1, 2].set_title('[1,4]')\n",
    "    axs[2, 0].scatter(temp[:n_samples-1,2], temp[:n_samples-1,3], s=10, alpha=0.5)\n",
    "    axs[2, 0].scatter(temp1[:n_samples-1,2], temp1[:n_samples-1,3], s=10, alpha=0.5)\n",
    "    axs[2, 0].set_title('[2,3]')\n",
    "    axs[2, 1].scatter(temp[:n_samples-1,2], temp[:n_samples-1,4], s=10, alpha=0.5)\n",
    "    axs[2, 1].scatter(temp1[:n_samples-1,2], temp1[:n_samples-1,4], s=10, alpha=0.5)\n",
    "    axs[2, 1].set_title('[2,4]')\n",
    "    axs[2, 2].scatter(temp[:n_samples-1,2], temp[:n_samples-1,5], s=10, alpha=0.5)\n",
    "    axs[2, 2].scatter(temp1[:n_samples-1,2], temp1[:n_samples-1,5], s=10, alpha=0.5)\n",
    "    axs[2, 2].set_title('[2,5]')\n",
    "    # print(temp.shape)\n",
    "    # ax.scatter(temp[:n_samples-1,0], temp[:n_samples-1,1], s=20)\n",
    "    # ax.scatter(temp1[:n_samples-1,0], temp[:n_samples-1,1], s=20)\n",
    "    plt.savefig(os.path.join(directory,'_raw_embedding_' + string_name + '_' + str(epoch) + '.png'))\n",
    "    # ax.set(title='Raw embedding (1st vs 2nd')\n",
    "    # np.std(temp, axis=0)\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "    # n_samples = 1026\n",
    "    gamma=0\n",
    "    # print('sent_src_idx[:n_samples].size(): {}'.format(sent_src_idx.size()))\n",
    "    phate_operator = phate.PHATE(n_components=2, gamma=gamma, n_jobs=-1) #setting just t\n",
    "    data_phate = phate_operator.fit_transform(sent_idx.cpu().detach().numpy())\n",
    "\n",
    "    ### Add some landmarks for reference\n",
    "    idx_tgt_words=[]\n",
    "    idx_src_words=[]\n",
    "    tgt_words_land = word_list.iloc[:,1] #['January', 'March', 'April', 'May'] #word_list.ix[:,1]\n",
    "    src_words_land = word_list.iloc[:,0] #['janvier', 'mars', 'avril', 'mai'] #word_list.ix[:,0]\n",
    "    # len(tgt_words_land)\n",
    "    for i in range(len(tgt_words_land)-1):\n",
    "        for j in range(0,n_samples-1): #scanning TGT\n",
    "            if tgt_words_land[i]==sent[j]: #if this word is in word_list, find it in french as well\n",
    "                for k in range(n_samples,2*n_samples-1):\n",
    "                    if src_words_land[i]==sent[k]:\n",
    "    #                     print('word[j={},k={}]: {},{}'.format(j,k,sent[j],sent[k]))\n",
    "                        idx_tgt_words.append(j)\n",
    "                        idx_src_words.append(k)\n",
    "\n",
    "    # Plotting the overalpped phate\n",
    "    # sent[0]\n",
    "    fig, ax = plt.subplots(figsize=(12, 12), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    ax.scatter(data_phate[:n_samples-1,0], data_phate[:n_samples-1,1], s=20)\n",
    "    ax.scatter(data_phate[n_samples:2*n_samples-1,0], data_phate[n_samples:2*n_samples-1,1], s=20, color='g')\n",
    "\n",
    "    ax.scatter(data_phate[idx_tgt_words,0], data_phate[idx_tgt_words,1], s=20, color='r')\n",
    "    for i in range(0,len(idx_tgt_words)-1):\n",
    "        ax.annotate(sent[idx_tgt_words[i]], (data_phate[idx_tgt_words[i],0], data_phate[idx_tgt_words[i],1]), fontsize=15)\n",
    "        \n",
    "    ax.scatter(data_phate[idx_src_words,0], data_phate[idx_src_words,1], s=20, color='tab:orange')\n",
    "    for i in range(0,len(idx_src_words)-1):\n",
    "        ax.annotate(sent[idx_src_words[i]], (data_phate[idx_src_words[i],0], data_phate[idx_src_words[i],1]), fontsize=15)\n",
    "    ax.set_title(string_name+'_EN_FR_phate_' + string_name + '_' + str(epoch))\n",
    "    plt.savefig(os.path.join(directory,'_EN_FR_phate_' + string_name + '_' + str(epoch) + '.png'))\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "    #Using UMAP\n",
    "    reducer = umap.UMAP()\n",
    "    data_phate = reducer.fit_transform(sent_idx.cpu().detach().numpy())\n",
    "    fig, ax = plt.subplots(figsize=(12, 12), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    ax.scatter(data_phate[n_samples:2*n_samples-1,0], data_phate[n_samples:2*n_samples-1,1], s=10, color='g')\n",
    "    ax.scatter(data_phate[:n_samples-1,0], data_phate[:n_samples-1,1], s=10, marker='*')\n",
    "                \n",
    "    ax.scatter(data_phate[idx_tgt_words,0], data_phate[idx_tgt_words,1], s=10, color='r')\n",
    "    for i in range(0,len(idx_tgt_words)-1):\n",
    "        ax.annotate(sent[idx_tgt_words[i]], (data_phate[idx_tgt_words[i],0], data_phate[idx_tgt_words[i],1]), fontsize=15)\n",
    "        \n",
    "    ax.scatter(data_phate[idx_src_words,0], data_phate[idx_src_words,1], s=10, color='tab:orange')\n",
    "    for i in range(0,len(idx_src_words)-1):\n",
    "        ax.annotate(sent[idx_src_words[i]], (data_phate[idx_src_words[i],0], data_phate[idx_src_words[i],1]), fontsize=15)\n",
    "    ax.set_title(string_name+'_EN_FR_umap_landmarks_' + string_name + '_' + str(epoch))\n",
    "    plt.savefig(os.path.join(directory,'_EN_FR_umap_landmarks_' + string_name + '_' + str(epoch) + '.png'))\n",
    "    plt.close('all')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 12), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    ax.scatter(data_phate[:n_samples-1,0], data_phate[:n_samples-1,1], s=10, marker='*')\n",
    "    ax.scatter(data_phate[idx_tgt_words,0], data_phate[idx_tgt_words,1], s=10, color='r')\n",
    "    for i in range(0,len(idx_tgt_words)-1):\n",
    "        ax.annotate(sent[idx_tgt_words[i]], (data_phate[idx_tgt_words[i],0], data_phate[idx_tgt_words[i],1]), fontsize=12)\n",
    "    ax.set_title(string_name+'_EN_umap_landmarks_' + string_name + '_' + str(epoch))\n",
    "    plt.savefig(os.path.join(directory,'_EN_umap_landmarks_' + string_name + '_' + str(epoch) + '.png'))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    ax.scatter(data_phate[n_samples:2*n_samples-1,0], data_phate[n_samples:2*n_samples-1,1], s=10, color='g')\n",
    "    ax.scatter(data_phate[idx_src_words,0], data_phate[idx_src_words,1], s=10, color='tab:orange')\n",
    "    for i in range(0,len(idx_src_words)-1):\n",
    "        ax.annotate(sent[idx_src_words[i]], (data_phate[idx_src_words[i],0], data_phate[idx_src_words[i],1]), fontsize=12)\n",
    "    ax.set_title(string_name+'_FR_umap_landmarks_' + string_name + '_' + str(epoch))\n",
    "    plt.savefig(os.path.join(directory,'_FR_umap_landmarks_' + string_name + '_' + str(epoch) + '.png'))\n",
    "    plt.close('all')\n",
    "\n",
    "    #Using PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    data_phate = pca.fit_transform(sent_idx.cpu().detach().numpy())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    ax.scatter(data_phate[n_samples:2*n_samples-1,0], data_phate[n_samples:2*n_samples-1,1], s=10, color='g')\n",
    "    ax.scatter(data_phate[:n_samples-1,0], data_phate[:n_samples-1,1], s=10, marker='*')\n",
    "    ax.scatter(data_phate[idx_tgt_words,0], data_phate[idx_tgt_words,1], s=10, color='r')\n",
    "    for i in range(0,len(idx_tgt_words)-1):\n",
    "        ax.annotate(sent[idx_tgt_words[i]], (data_phate[idx_tgt_words[i],0], data_phate[idx_tgt_words[i],1]), fontsize=15)\n",
    "        \n",
    "    ax.scatter(data_phate[idx_src_words,0], data_phate[idx_src_words,1], s=10, color='tab:orange')\n",
    "    for i in range(0,len(idx_src_words)-1):\n",
    "        ax.annotate(sent[idx_src_words[i]], (data_phate[idx_src_words[i],0], data_phate[idx_src_words[i],1]), fontsize=15)\n",
    "    ax.set_title(string_name+'_EN_FR_pca_landmarks_' + string_name + '_' + str(epoch))\n",
    "    plt.savefig(os.path.join(directory,'_EN_FR_pca_landmarks_' + string_name + '_' + str(epoch) + '.png'))\n",
    "    plt.close('all')\n",
    "\n",
    "    # Plotting the overalpped phate\n",
    "    # sent[0]\n",
    "    fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    ax.scatter(data_phate[:n_samples-1,0], data_phate[:n_samples-1,1], s=10, marker='*')\n",
    "    len(idx_src_words)\n",
    "    len(idx_src_words)\n",
    "    ax.scatter(data_phate[idx_tgt_words,0], data_phate[idx_tgt_words,1], s=10, color='r')\n",
    "    for i in range(0,len(idx_tgt_words)-1):\n",
    "        ax.annotate(sent[idx_tgt_words[i]], (data_phate[idx_tgt_words[i],0], data_phate[idx_tgt_words[i],1]), fontsize=12)\n",
    "    ax.set_title(string_name+'_EN_pca_landmarks_' + string_name + '_' + str(epoch))\n",
    "    plt.savefig(os.path.join(directory,'_EN_pca_landmarks_' + string_name + '_' + str(epoch) + '.png'))\n",
    "    plt.close('all')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    ax.scatter(data_phate[n_samples:2*n_samples-1,0], data_phate[n_samples:2*n_samples-1,1], s=10, color='g')\n",
    "    ax.scatter(data_phate[idx_src_words,0], data_phate[idx_src_words,1], s=10, color='tab:orange')\n",
    "    for i in range(0,len(idx_src_words)-1):\n",
    "        ax.annotate(sent[idx_src_words[i]], (data_phate[idx_src_words[i],0], data_phate[idx_src_words[i],1]), fontsize=12)\n",
    "    ax.set_title(string_name+'_FR_pca_landmarks_' + string_name + '_' + str(epoch))\n",
    "    plt.savefig(os.path.join(directory,'_FR_pca_landmarks_' + string_name + '_' + str(epoch) + '.png'))\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def train_generator(optimizer, french_data, english_data):\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     d_french = discriminator(french_data)\n",
    "#     d_english = discriminator(english_data)\n",
    "    \n",
    "#     loss = torch.mean((d_french - d_english)**2) # minimize difference between french and english\n",
    "    \n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     return loss\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        # out = model.forward(batch.src.to(device), batch.trg.to(device), batch.src_mask.to(device), batch.trg_mask.to(device))\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        # print('(in encoder) src.size: {}'.format(src.size()))\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        # print('(in encoder) x.size: {}'.format(x.size()))\n",
    "        return self.norm(x)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        # print('(in decoder - before layer) x.size: {}'.format(x.size()))\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        # print('(in decoder) x.size: {}'.format(x.size()))\n",
    "        return self.norm(x)\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = 1 / (10000 ** (torch.arange(0., d_model, 2) / d_model))\n",
    "        # div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                             # -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "\n",
    "\n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model\n",
    "\n",
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad): \n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask\n",
    "\n",
    "def run_epoch(data_iter, model, loss_compute, device, SRC, TGT, epoch, n_epochs):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    total_loss_generator=0\n",
    "    total_loss_transformer=0\n",
    "    total_loss_MMD = 0\n",
    "    total_loss_justTransf = 0\n",
    "    tokens = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        # batch = batch.cuda()\n",
    "        # words = word_list.sample(frac=0.05) #Maybe n=100 words as landmarks is not enough... Try frac=0.5\n",
    "        \n",
    "        # #using landmarks\n",
    "        # src_words = words.ix[:,0] \n",
    "        # tgt_words = words.ix[:,1]\n",
    "        # n_samples_mmd = 1000  #Number of samples\n",
    "        # word_list = [sample(SRC.vocab.itos,n_samples_mmd), sample(TGT.vocab.itos,n_samples_mmd)]\n",
    "\n",
    "        # src_words = sample(SRC.vocab.itos,n_samples_mmd)\n",
    "        # tgt_words = sample(TGT.vocab.itos,n_samples_mmd)\n",
    "\n",
    "        # src_words = torch.LongTensor([[SRC.vocab.stoi[w] for w in src_words]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "        # src_words = Variable(src_words)\n",
    "        # tgt_words = torch.LongTensor([[TGT.vocab.stoi[w] for w in tgt_words]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "        # tgt_words = Variable(tgt_words)\n",
    "        # print(\"tgt_words.size(): {}\".format(tgt_words.size()))\n",
    "        # print(\"tgt_words: {}\".format(tgt_words))\n",
    "        \n",
    "        # print('batch.trg.data: {}'.format(batch.trg.data))\n",
    "        # tgt_words = torch.unique(batch.trg.data, sorted=False) #Extracting unique words from the batch \n",
    "        # src_words = torch.unique(batch.src.data, sorted=False) \n",
    "\n",
    "        # Using GANs#\n",
    "        # tgt_words = torch.reshape(batch.trg.data, (-1,))\n",
    "        # tgt_words = tgt_words[tgt_words>3]\n",
    "        # src_words = torch.reshape(batch.src.data, (-1,))\n",
    "        # src_words = src_words[src_words>3]\n",
    "        # min_words = min(tgt_words.size(0), src_words.size(0))\n",
    "        # tgt_words = tgt_words[:min_words]\n",
    "        # src_words = src_words[:min_words]\n",
    "        # \\Using GANs#\n",
    "\n",
    "\n",
    "        # print(\"tgt_words.size(): {}, src_words.size(): {}, min_words: {}\".format(tgt_words.size(), src_words.size(), min_words))\n",
    "        # print('tgt_words: {}'.format(tgt_words))\n",
    "        # print('batch.src.data.size(): {}'.format(batch.src.data.size()))\n",
    "        # break\n",
    "        # print('batch.src: {}'.format(batch.src))\n",
    "        # print('Number of sentences: {}'.format(batch.trg.size(0))) #Number of sentences in this batch (batch.trg.size(0) and batch.src.size(0) are equal)\n",
    "        # print('batch.src.size(): {}'.format(batch.src.size()))\n",
    "        # if i==1:\n",
    "        #     print(\"Target:\", end=\"\\t\")\n",
    "        #     for j in range(1, batch.trg.size(1)): #Maximum sentence length in this batch\n",
    "        #         sym = TGT.vocab.itos[batch.trg.data[0, j]] #Translating indexes to words of the first english sentence in this batch.\n",
    "        #         if sym == \"</s>\": break\n",
    "        #         # print(sym, end =\" \")\n",
    "        #         print(\"(j={}) {}\".format(batch.trg.data[0, j],sym))\n",
    "        #     print()\n",
    "        # if i==1:\n",
    "        #     print(\"Target:\", end=\"\\t\")\n",
    "        #     for j in range(1, tgt_words.size(0)): #Maximum sentence length in this batch\n",
    "        #         sym = TGT.vocab.itos[tgt_words[j]] #Translating indexes to words of the first english sentence in this batch.\n",
    "        #         if sym == \"</s>\": break\n",
    "        #         # print(sym, end =\" \")\n",
    "        #         print(\"(j={}) {}\".format(tgt_words[j],sym))\n",
    "        #     print()\n",
    "        #     print(\"Source:\", end=\"\\t\")\n",
    "        #     for j in range(1, src_words.size(0)): #Maximum sentence length in this batch\n",
    "        #         sym = SRC.vocab.itos[src_words[j]] #Translating indexes to words of the first english sentence in this batch.\n",
    "        #         if sym == \"</s>\": break\n",
    "        #         # print(sym, end =\" \")\n",
    "        #         print(\"(j={}) {}\".format(src_words[j],sym))\n",
    "        #     print()\n",
    "        # print(\"i={}\\n\".format(i))\n",
    "        # if i==2:\n",
    "        #     break\n",
    "\n",
    "        # Select src_words and tgt_words from word_list (500 words / 50 for every epoch)\n",
    "        out = model.forward(batch.src.to(device), batch.trg.to(device), batch.src_mask.to(device), batch.trg_mask.to(device))\n",
    "        # print('out.size(): {}'.format(out.size()))\n",
    "#         try:\n",
    "        #### Using MMD ####\n",
    "        # loss, loss_MMD, loss_trans = loss_compute(out, batch.trg_y.to(device), batch.ntokens.to(device), src_words, tgt_words) \n",
    "        #### Using MMD ####\n",
    "\n",
    "        # #### Using GANs ####\n",
    "        # #Compute embeddings\n",
    "        # embed_src = model.src_embed[0].lut(batch.src.to(device)).cpu().detach()\n",
    "        # # embed_src = embed_src.to(device)\n",
    "        # embed_tgt = model.tgt_embed[0].lut(batch.trg.to(device)).cpu().detach()\n",
    "        # # embed_tgt = embed_tgt.to(device)\n",
    "        # #Compute loss for the discriminator\n",
    "        # loss_discriminator, d_pred_french, d_pred_english = train_discriminator(d_optimizer, batch.src.to(device), batch.trg.to(device))\n",
    "        # #Compute transformer loss (full step, thus including update of the embedding) and generator loss\n",
    "        # # loss, loss_generator, loss_transformer = loss_compute(out, batch.trg_y.to(device), batch.ntokens.to(device), src_words, tgt_words) \n",
    "        # #### \\Using GANs ####\n",
    "\n",
    "        # self, x, y, norm, src_words, tgt_words\n",
    "        # loss.item(), loss_generator.item(),  loss_transformer.item()\n",
    "        if EUCLDN:\n",
    "            loss, loss_generator, loss_transformer = loss_compute(out, batch.trg_y.to(device), batch.ntokens.to(device), batch.src.to(device), batch.trg.to(device)) \n",
    "            total_loss_generator += loss_generator\n",
    "        elif MMD:\n",
    "            loss, loss_MMD, loss_transformer = loss_compute(out, batch.trg_y.to(device), batch.ntokens.to(device), batch.src.to(device), batch.trg.to(device)) \n",
    "            total_loss_MMD += loss_MMD\n",
    "        else:\n",
    "            loss, loss_justTransf, loss_transformer = loss_compute(out, batch.trg_y.to(device), batch.ntokens.to(device), batch.src.to(device), batch.trg.to(device)) \n",
    "            total_loss_justTransf += loss_justTransf\n",
    "        # loss, loss_land, loss_trans = loss_compute(out, batch.trg_y.to(device), batch.ntokens.to(device), batch.src.to(device), batch.trg.to(device))\n",
    "#         except:\n",
    "#             print('Unexpected error: {}'.format(sys.exc_info()[0]))\n",
    "#             del batch\n",
    "        # print('Loss: {}'.format(str(loss)))\n",
    "        total_loss += loss\n",
    "        total_loss_transformer+= loss_transformer\n",
    "        total_tokens += batch.ntokens.item()\n",
    "        tokens += batch.ntokens.item()\n",
    "        \n",
    "\n",
    "        if i % 100 == 0:\n",
    "            elapsed = time.time() - start\n",
    "            # print(batch.ntokens.item())\n",
    "            # print('Loss: {}'.format(loss))\n",
    "            # print('Epoch Step: {} Loss: {}'.format(i, loss / batch.ntokens.item()))\n",
    "            if EUCLDN:\n",
    "                print('Epoch Step: {} Loss: {:.4f} (loss_gener: {:.2e}, loss_trans: {:.4f}) Tokens per Sec: {:.4f}'.format(i, loss, loss_generator, loss_transformer, tokens / elapsed))\n",
    "            elif MMD:\n",
    "                print('Epoch Step: {} Loss: {:.4f} (loss_MMD: {:.4f}, loss_trans: {:.4f}) Tokens per Sec: {:.4f}'.format(i, loss, loss_MMD, loss_transformer, tokens / elapsed))\n",
    "            else:\n",
    "                print('Epoch Step: {} Loss: {:.4f} (loss_trans: {:.4f}) Tokens per Sec: {:.4f}'.format(i, loss, loss_transformer, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "\n",
    "        # logger.log(loss, loss_transformer, loss_MMD, loss_generator, epoch, i)\n",
    "        # Display Progress every few batches\n",
    "        # if i % 100 == 0: \n",
    "            # test_images = vectors_to_images(generator(test_noise))\n",
    "            # test_images = test_images.data\n",
    "            # logger.log_images(\n",
    "            #     test_images, num_test_samples, \n",
    "            #     epoch, n_batch, num_batches\n",
    "            # );\n",
    "            # Display status Logs\n",
    "            # logger.display_status(\n",
    "            #     epoch, n_epochs, i,\n",
    "            #     loss_transformer, loss_discriminator, loss_generator, d_pred_french, d_pred_english\n",
    "            # )\n",
    "    # loss_train, loss_total_train, loss_generator_train, loss_discriminator_train, loss_transformer_train\n",
    "    if EUCLDN:\n",
    "        return total_loss / total_tokens, loss, total_loss_generator / total_tokens, total_loss_transformer / total_tokens\n",
    "    elif MMD:\n",
    "        return total_loss / total_tokens, loss, total_loss_MMD/total_tokens, total_loss_transformer / total_tokens\n",
    "    else:\n",
    "        return total_loss / total_tokens, loss, total_loss_justTransf/total_tokens, total_loss_transformer / total_tokens\n",
    "\n",
    "global max_src_in_batch, max_tgt_in_batch\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    return max(src_elements, tgt_elements)\n",
    "\n",
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))\n",
    "\n",
    "def loss(x):\n",
    "    d = x + 3 * 1\n",
    "    predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d],\n",
    "                                 ])\n",
    "    #print(predict)\n",
    "    return crit(Variable(predict.log()),\n",
    "                 Variable(torch.LongTensor([1]))).item()\n",
    "    # return crit(Variable(predict.log()),\n",
    "    #              Variable(torch.LongTensor([1]))).data[0]\n",
    "\n",
    "#Finally an example\n",
    "def data_gen(V, batch, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10)))\n",
    "        data[:, 0] = 1\n",
    "        src = Variable(data, requires_grad=False)\n",
    "        tgt = Variable(data, requires_grad=False)\n",
    "        yield Batch(src, tgt, 0)\n",
    "\n",
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    # def __init__(self, generator, criterion, src_embed, tgt_embed, SRC, TGT, mmd, opt=None):\n",
    "    def __init__(self, generator, criterion, src_embed, tgt_embed, SRC, TGT, mmd, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.SRC = SRC\n",
    "        self.TGT = TGT\n",
    "        self.mmd=mmd\n",
    "        # self.discriminator = discriminator\n",
    "        # self.g_optimizer = g_optimizer\n",
    "        # self.loss_GAN = loss_GAN\n",
    "        # self.english_data_target = english_data_target\n",
    "        # self.mmd=mmd\n",
    "        self.opt = opt\n",
    "        \n",
    "    # def __call__(self, x, y, norm, src_words, tgt_words): #using landmarks\n",
    "    def __call__(self, x, y, norm, src_words, tgt_words):\n",
    "        # print('x.size(): {}'.format(x.size()))\n",
    "        x = self.generator(x)\n",
    "        # print('(post genertator) x.size(): {}'.format(x.size()))\n",
    "        # print('x.contiguous().view(-1, x.size(-1)).size(): {}'.format(x.contiguous().view(-1, x.size(-1)).size()))\n",
    "        # print('y.contiguous().view(-1).size(): {}'.format(y.contiguous().view(-1).size()))\n",
    "        loss_transformer = self.criterion(x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1))*weight_loss_transformer / norm\n",
    "        sigma_list = np.logspace(-3, 2, 10)\n",
    "        # Subset of words in english/french\n",
    "#         print('self.src_embed: {}'.format(self.src_embed))\n",
    "#         print('self.tgt_embed: {}'.format(self.tgt_embed))\n",
    "#         src_words.columns = ['words']\n",
    "#         print('src_words: \\n{}'.format(src_words))\n",
    "\n",
    "#         #### using landmarks\n",
    "#         src_words = src_words.values.tolist()\n",
    "#         tgt_words = tgt_words.values.tolist()\n",
    "# #         print('src_words: \\n{}'.format(src_words))\n",
    "        \n",
    "        # src_words = torch.LongTensor([[self.SRC.vocab.stoi[w] for w in src_words]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "        # src_words = Variable(src_words)\n",
    "        \n",
    "        # tgt_words = torch.LongTensor([[self.TGT.vocab.stoi[w] for w in tgt_words]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "        # tgt_words = Variable(tgt_words)\n",
    "\n",
    "        # loss_landmarks = 100000*torch.mean((embed_src - embed_tgt)**2)\n",
    "        # loss_landmarks = 100000*nn.MSELoss()(embed_src, embed_tgt) \n",
    "#         #### \\using landmarks\n",
    "          \n",
    "        # # #### using MMD #######\n",
    "        # # print('src_words: \\n{}'.format(src_words['french'].values))\n",
    "        # # src_words = torch.stack(src_words)\n",
    "        # # # print('src_words.size(): {}'.format(src_words.size()))\n",
    "        # # # print('tgt_words.size(): {}'.format(tgt_words.size()))\n",
    "        # embed_src = self.src_embed(src_words.to(device)).cpu()\n",
    "        # embed_tgt = self.tgt_embed(tgt_words.to(device)).cpu()\n",
    "        # # # print('embed_src.size(): {}'.format(embed_src.size()))\n",
    "        # # # print('embed_tgt.size(): {}'.format(embed_tgt.size()))\n",
    "        # # loss_MMD = self.mmd.mix_rbf_mmd2(embed_src.squeeze(), embed_tgt.squeeze(), sigma_list=sigma_list)\n",
    "        # # loss_MMD = weigth_MMD*loss_MMD\n",
    "        # # #### \\using MMD #######\n",
    "\n",
    "        # Using MMD (v2)\n",
    "        # print(\"tgt_words.size(): {}, src_words.size(): {}\".format(tgt_words.size(), src_words.size()))\n",
    "        \n",
    "\n",
    "        # batch_MMD_loss = []\n",
    "        # for j in range(0, src_words.size(0)):\n",
    "        #     # print(\"src_words.size(): {}\\n tgt_words.size(): {}\".format(src_words.size(), tgt_words.size()))\n",
    "        #     src_words2 = src_words[j,src_words[j,:]!=1] #1=<blank>\n",
    "        #     tgt_words2 = tgt_words[j,tgt_words[j,:]>3] #1=<blank>, 2=<s>, 3=</s>\n",
    "        #     # print(\"src_words2_orig: {}\\n tgt_words2_orig: {}\".format(src_words2, tgt_words2))\n",
    "        #     # print(\"src_words2.size(): {}\\n tgt_words2.size(): {}\".format(src_words2.size(), tgt_words2.size()))\n",
    "        #     min_words = min(tgt_words2.size(0), src_words2.size(0))\n",
    "        #     src_words2 = src_words2[torch.multinomial(src_words2.float(),min_words)]\n",
    "        #     tgt_words2 = tgt_words2[torch.multinomial(tgt_words2.float(),min_words)]\n",
    "        #     # tgt_words2 = tgt_words2[:,:min_words]\n",
    "        #     # src_words2 = src_words2[:,:min_words]\n",
    "        #     # print(\"Target:\", end=\"\\t\")\n",
    "        #     # for k in range(0, tgt_words2.size(0)): #Maximum sentence length in this batch\n",
    "        #     #     sym = TGT.vocab.itos[tgt_words2[k]] #Translating indexes to words of the first english sentence in this batch.\n",
    "        #     #     if sym == \"</s>\": break\n",
    "        #     #     # print(sym, end =\" \")\n",
    "        #     #     print(\"(j={}) {}\".format(tgt_words2[k],sym))\n",
    "        #     # print()\n",
    "        #     # print(\"Source:\", end=\"\\t\")\n",
    "        #     # for k in range(0, src_words2.size(0)): #Maximum sentence length in this batch\n",
    "        #     #     sym = SRC.vocab.itos[src_words2[k]] #Translating indexes to words of the first english sentence in this batch.\n",
    "        #     #     if sym == \"</s>\": break\n",
    "        #     #     # print(sym, end =\" \")\n",
    "        #     #     print(\"(j={}) {}\".format(src_words2[k],sym))\n",
    "        #     # print()\n",
    "        #     # print(\"src_words.size(): {}, tgt_words.size(): {}\".format(src_words.size(), tgt_words.size()))\n",
    "        #     # print(\"src_words2: {}\\n tgt_words2: {}\".format(src_words2, tgt_words2))\n",
    "        #     embed_src = model.src_embed[0].lut(src_words2.to(device))\n",
    "        #     embed_tgt = model.tgt_embed[0].lut(tgt_words2.to(device))\n",
    "        #     # print(\"tgt_words2.size(): {}, src_words2.size(): {}, embed_src.size: {}\".format(tgt_words2.size(), src_words2.size(), embed_src.size()))\n",
    "        #     batch_MMD_loss.append(self.mmd.mix_rbf_mmd2(embed_src, embed_tgt, sigma_list=sigma_list))\n",
    "        #     # break\n",
    "        # loss_MMD =  torch.mean(torch.stack(batch_MMD_loss)).to(device)*weight_loss_MMD\n",
    "        # # print(\"loss_MMD: {}\".format(loss_MMD))\n",
    "        # # print(\"loss_transformer: {}\".format(loss_transformer))\n",
    "        # loss = weight_loss_transformer*loss_transformer + loss_MMD\n",
    "\n",
    "        # # \\Using MMD (v2)\n",
    "\n",
    "        # # Using MSE for sentence pairs#\n",
    "        \n",
    "        # batch_MSE_loss = []\n",
    "        # for j in range(1, src_words.size(0)):\n",
    "        #     # print(\"src_words: {}\\n, tgt_words: {}\".format(src_words, tgt_words))\n",
    "        #     src_words2 = src_words[j,:]\n",
    "        #     tgt_words2 = tgt_words[j,:]\n",
    "        #     # print(\"src_words.size(): {}, tgt_words.size(): {}\".format(src_words.size(), tgt_words.size()))\n",
    "        #     # print(\"src_words: {}\\n tgt_words: {}\".format(src_words, tgt_words))\n",
    "        #     embed_src = torch.mean(model.src_embed[0].lut(src_words2.to(device)).cpu().detach())\n",
    "        #     embed_tgt = torch.mean(model.tgt_embed[0].lut(tgt_words2.to(device)).cpu())\n",
    "        #     # print(\"tgt_words.size(): {}, src_words.size(): {}, embed_src: {}\".format(tgt_words.size(), src_words.size(), embed_src))\n",
    "        #     batch_MSE_loss.append(nn.MSELoss()(embed_src, embed_tgt))\n",
    "        # loss_MSE =  torch.mean(torch.stack(batch_MSE_loss)).to(device)*weight_loss_MSE\n",
    "        # # print(\"loss_MSE: {}\".format(loss_MSE))\n",
    "        # # print(\"loss_transformer: {}\".format(loss_transformer))\n",
    "        \n",
    "        # loss = weight_loss_transformer*loss_transformer + loss_MSE\n",
    "        # # \\Using MSE for sentence pairs#        \n",
    "        \n",
    "        #### Using GANs ####\n",
    "        # loss_generator = self.train_generator_gan(self.g_optimizer, embed_src, embed_tgt)\n",
    "        if EUCLDN:\n",
    "            batch_GAN_loss = []\n",
    "            # try:\n",
    "            for j in range(1, src_words.size(0)-1):\n",
    "\n",
    "                # 1st pair of sentences \n",
    "                src_words_1 = src_words[j,src_words[j,:]!=1] #1=<blank>\n",
    "                tgt_words_1 = tgt_words[j,tgt_words[j,:]>3] #1=<blank>, 2=<s>, 3=</s>\n",
    "                # src_words_2 = src_words[j+1,src_words[j+1,:]!=1] #1=<blank>\n",
    "                # tgt_words_2 = tgt_words[j+1,tgt_words[j+1,:]>3] #1=<blank>, 2=<s>, 3=</s>\n",
    "                # print(\"src_words_1: {}\".format(src_words_1))\n",
    "                # print(\"src_words_1.size(): {}\".format(src_words_1.size()))\n",
    "                \n",
    "                # min_words = min(tgt_words_1.size(0), src_words_1.size(0),tgt_words_2.size(0), src_words_2.size(0))\n",
    "                # src_words_1 = src_words_1[torch.multinomial(src_words_1.float(),min_words)]\n",
    "                # tgt_words_1 = tgt_words_1[torch.multinomial(tgt_words_1.float(),min_words)]\n",
    "                # embed_src_1 = model.src_embed[0].lut(src_words_1.to(device)).cpu()\n",
    "                # print(\"embed_src_1: {}\".format(embed_src_1))\n",
    "                # print(\"embed_src_1.size(): {}\".format(embed_src_1.size()))\n",
    "                embed_src_1 = torch.mean(model.src_embed[0].lut(src_words_1.to(device)).cpu(),0)\n",
    "                embed_tgt_1 = torch.mean(model.tgt_embed[0].lut(tgt_words_1.to(device)).cpu(),0)\n",
    "                # print(\"embed_src_1: {}\".format(embed_src_1))\n",
    "                # print(\"embed_src_1.size(): {}\".format(embed_src_1.size()))\n",
    "\n",
    "                # 2nd pair of sentences \n",
    "                # src_words_2 = src_words_2[torch.multinomial(src_words_2.float(),min_words)]\n",
    "                # tgt_words_2 = tgt_words_2[torch.multinomial(tgt_words_2.float(),min_words)]\n",
    "                # embed_src_2 = torch.mean(model.src_embed[0].lut(src_words_2.to(device)).cpu(),0)\n",
    "                # embed_tgt_2 = torch.mean(model.tgt_embed[0].lut(tgt_words_2.to(device)).cpu(),0)\n",
    "            # print(\"src_words: {}\".format(src_words))\n",
    "            # print(\"src_words.size(): {}\".format(src_words.size()))\n",
    "            # embed_src = model.src_embed[0].lut(src_words.to(device)).cpu()\n",
    "            # print(\"embed_src: {}\".format(embed_src))\n",
    "            # print(\"embed_src.size(): {}\".format(embed_src.size()))\n",
    "            # embed_src = torch.mean(model.src_embed[0].lut(src_words.to(device)).cpu(),0)\n",
    "            # embed_tgt = torch.mean(model.tgt_embed[0].lut(tgt_words.to(device)).cpu(),0)\n",
    "            # print(\"embed_src: {}\".format(embed_src))\n",
    "            # print(\"embed_src.size(): {}\".format(embed_src.size()))\n",
    "                # prediction_french = self.discriminator(embed_src)\n",
    "                # prediction_english = self.discriminator(embed_tgt)\n",
    "                # prediction_french = embed_src_1\n",
    "                # prediction_english = embed_tgt_1\n",
    "                # loss_generator = torch.mean((d_french - d_english)**2) # minimize difference between french and english\n",
    "                # loss_generator = self.loss_GAN(prediction_english, french_data_target(prediction_english.squeeze().size(0)))\n",
    "                # print(\"torch.norm(prediction_english - prediction_french,p=2): {}\".format(torch.norm(prediction_english - prediction_french,p=2)))\n",
    "                # loss_generator = 2*torch.norm(prediction_english - prediction_french,p=2) - torch.norm(prediction_english,p=2) - torch.norm(prediction_french,p=2)\n",
    "                # loss_generator = torch.norm(embed_tgt_1 - embed_src_1,p=2) + torch.norm(embed_tgt_2 - embed_src_2,p=2) - torch.norm(embed_tgt_1 - embed_src_2,p=2) - torch.norm(embed_src_1 - embed_tgt_2,p=2)\n",
    "                loss_generator = -torch.dot(embed_tgt_1, embed_src_1)\n",
    "                # print(\"embed_src_1.size(): {} , embed_tgt_1.size(): {}, loss_generator: {}\".format(embed_src_1.size(), embed_tgt_1.size(),loss_generator))\n",
    "                # loss_generator = (embed_tgt_1 - embed_src_1)**2 + (embed_tgt_2 - embed_src_2)**2 - (embed_tgt_1 - embed_tgt_2)**2 - (embed_src_1 - embed_src_2)**2\n",
    "                # loss_generator = 2*(torch.mean(prediction_french) - torch.mean(prediction_english))**2 - torch.mean(prediction_english)**2 - torch.mean(prediction_french)**2\n",
    "                # print(\"prediction_english: {}\".format(prediction_english))\n",
    "                # print(\"prediction_french: {}\".format(prediction_french))\n",
    "                # loss_generator = self.loss_GAN(prediction_english, prediction_french.detach())\n",
    "                # loss_generator.backward()\n",
    "                batch_GAN_loss.append(loss_generator)\n",
    "                # print(\"len(batch_GAN_loss): {}\".format(len(batch_GAN_loss)))\n",
    "            loss_generator = torch.mean(torch.stack(batch_GAN_loss)).to(device)*weight_loss_generator\n",
    "            loss = loss_transformer + loss_generator\n",
    "        elif MMD:\n",
    "            batch_MMD_loss = []\n",
    "            for j in range(0, src_words.size(0)):\n",
    "                # print(\"src_words.size(): {}\\n tgt_words.size(): {}\".format(src_words.size(), tgt_words.size()))\n",
    "                src_words2 = src_words[j,src_words[j,:]!=1] #1=<blank>\n",
    "                tgt_words2 = tgt_words[j,tgt_words[j,:]>3] #1=<blank>, 2=<s>, 3=</s>\n",
    "                # print(\"src_words2_orig: {}\\n tgt_words2_orig: {}\".format(src_words2, tgt_words2))\n",
    "                # print(\"src_words2.size(): {}\\n tgt_words2.size(): {}\".format(src_words2.size(), tgt_words2.size()))\n",
    "                min_words = min(tgt_words2.size(0), src_words2.size(0))\n",
    "                src_words2 = src_words2[torch.multinomial(src_words2.float(),min_words)]\n",
    "                tgt_words2 = tgt_words2[torch.multinomial(tgt_words2.float(),min_words)]\n",
    "                # tgt_words2 = tgt_words2[:,:min_words]\n",
    "                # src_words2 = src_words2[:,:min_words]\n",
    "                # print(\"Target:\", end=\"\\t\")\n",
    "                # for k in range(0, tgt_words2.size(0)): #Maximum sentence length in this batch\n",
    "                #     sym = TGT.vocab.itos[tgt_words2[k]] #Translating indexes to words of the first english sentence in this batch.\n",
    "                #     if sym == \"</s>\": break\n",
    "                #     # print(sym, end =\" \")\n",
    "                #     print(\"(j={}) {}\".format(tgt_words2[k],sym))\n",
    "                # print()\n",
    "                # print(\"Source:\", end=\"\\t\")\n",
    "                # for k in range(0, src_words2.size(0)): #Maximum sentence length in this batch\n",
    "                #     sym = SRC.vocab.itos[src_words2[k]] #Translating indexes to words of the first english sentence in this batch.\n",
    "                #     if sym == \"</s>\": break\n",
    "                #     # print(sym, end =\" \")\n",
    "                #     print(\"(j={}) {}\".format(src_words2[k],sym))\n",
    "                # print()\n",
    "                # print(\"src_words.size(): {}, tgt_words.size(): {}\".format(src_words.size(), tgt_words.size()))\n",
    "                # print(\"src_words2: {}\\n tgt_words2: {}\".format(src_words2, tgt_words2))\n",
    "                embed_src = model.src_embed[0].lut(src_words2.to(device))\n",
    "                embed_tgt = model.tgt_embed[0].lut(tgt_words2.to(device))\n",
    "                # print(\"tgt_words2.size(): {}, src_words2.size(): {}, embed_src.size: {}\".format(tgt_words2.size(), src_words2.size(), embed_src.size()))\n",
    "                batch_MMD_loss.append(self.mmd.mix_rbf_mmd2(embed_src, embed_tgt, sigma_list=sigma_list))\n",
    "                # break\n",
    "            loss_MMD =  torch.mean(torch.stack(batch_MMD_loss)).to(device)*weight_loss_MMD\n",
    "            loss = loss_transformer + loss_MMD\n",
    "        else:\n",
    "            batch_justTransf_loss = []\n",
    "            for j in range(0, src_words.size(0)):\n",
    "                # print(\"src_words.size(): {}\\n tgt_words.size(): {}\".format(src_words.size(), tgt_words.size()))\n",
    "                src_words2 = src_words[j,src_words[j,:]!=1] #1=<blank>\n",
    "                tgt_words2 = tgt_words[j,tgt_words[j,:]>3] #1=<blank>, 2=<s>, 3=</s>\n",
    "                # print(\"src_words2_orig: {}\\n tgt_words2_orig: {}\".format(src_words2, tgt_words2))\n",
    "                # print(\"src_words2.size(): {}\\n tgt_words2.size(): {}\".format(src_words2.size(), tgt_words2.size()))\n",
    "                min_words = min(tgt_words2.size(0), src_words2.size(0))\n",
    "                src_words2 = src_words2[torch.multinomial(src_words2.float(),min_words)]\n",
    "                tgt_words2 = tgt_words2[torch.multinomial(tgt_words2.float(),min_words)]\n",
    "                \n",
    "                embed_src = model.src_embed[0].lut(src_words2.to(device))\n",
    "                embed_tgt = model.tgt_embed[0].lut(tgt_words2.to(device))\n",
    "                # print(\"tgt_words2.size(): {}, src_words2.size(): {}, embed_src.size: {}\".format(tgt_words2.size(), src_words2.size(), embed_src.size()))\n",
    "                batch_justTransf_loss.append(self.mmd.mix_rbf_mmd2(embed_src, embed_tgt, sigma_list=sigma_list))\n",
    "                # break\n",
    "            loss_justTransf =  torch.mean(torch.stack(batch_justTransf_loss)).to(device)*weight_loss_MMD\n",
    "\n",
    "            loss = loss_transformer\n",
    "        # except: # in case the batch_GAN_loss comes empty\n",
    "        #     print('error with batch_GAN_loss')\n",
    "        #     try:\n",
    "        #         print(\"loss_generator: {}\".format(loss_generator))\n",
    "        #     except:\n",
    "        #         print(\"loss_generator=0\")\n",
    "        #         loss_generator=torch.cuda.FloatTensor([0])\n",
    "        \n",
    "        #### \\Using GANs ####\n",
    "\n",
    "        # print('loss_landmarks: {}'.format(loss_landmarks))\n",
    "        # print(\"loss.item(): {}, loss_MMD.item(): {},  loss_transformer.item(): {}\".format(loss.item(), loss_MMD.item(),  loss_transformer.item()))\n",
    "        loss.backward()\n",
    "\n",
    "        # print('Norm: {}'.format(str(norm)))\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "            # self.g_optimizer.step()\n",
    "            # self.g_optimizer.zero_grad()\n",
    "        # print('Loss: {}'.format(str(loss.detach().numpy())))\n",
    "        # print('Loss: {}'.format(str(loss.item())))\n",
    "        # print('Loss*norm: {}'.format(str(loss.item() * norm.item())))\n",
    "        # return loss.data[0] * norm #Original function\n",
    "        # loss = loss*norm\n",
    "        if EUCLDN:\n",
    "            return loss.item(), loss_generator.item(),  loss_transformer.item()\n",
    "        elif MMD:\n",
    "            return loss.item(), loss_MMD.item(),  loss_transformer.item()\n",
    "        else:\n",
    "            return loss.item(),  loss_transformer.item(), loss_transformer.item()\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "#         print('out_dim: {}'.format(len(out)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys\n",
    "\n",
    "class MyIterator(data.Iterator):\n",
    "    def create_batches(self):\n",
    "        if self.train:\n",
    "            def pool(d, random_shuffler):\n",
    "                for p in data.batch(d, self.batch_size * 100):\n",
    "                    p_batch = data.batch(\n",
    "                        sorted(p, key=self.sort_key),\n",
    "                        self.batch_size, self.batch_size_fn)\n",
    "                    for b in random_shuffler(list(p_batch)):\n",
    "                        yield b\n",
    "            self.batches = pool(self.data(), self.random_shuffler)\n",
    "            \n",
    "        else:\n",
    "            self.batches = []\n",
    "            for b in data.batch(self.data(), self.batch_size,\n",
    "                                          self.batch_size_fn):\n",
    "                self.batches.append(sorted(b, key=self.sort_key))\n",
    "\n",
    "def rebatch(pad_idx, batch):\n",
    "    \"Fix order in torchtext to match ours\"\n",
    "    src, trg = batch.src.transpose(0, 1), batch.trg.transpose(0, 1)\n",
    "    return Batch(src, trg, pad_idx)\n",
    "\n",
    "print('\\nDone defining functions...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = pd.read_csv('/gpfs/ysm/home/ahf38/project/word_embed_align/word_list.csv')\n",
    "word_list.columns = ['french', 'english']\n",
    "# print(word_list.shape)\n",
    "# print(word_list.head(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:\n",
      " number_of_lines: (919200, 4)\n",
      " batch_size: 2500\n",
      " weight_loss_transformer: 1\n",
      " weight_loss_MMD: 10\n",
      " n_epochs: 10000\n",
      " patience: 100\n",
      "Vocabulary is built\n"
     ]
    }
   ],
   "source": [
    "# europarl_en = open('/home/antonio/Documents/MovingMNIST/europarl-v7.fr-en.en', encoding='utf-8').read().split('\\n')\n",
    "# europarl_fr = open('/home/antonio/Documents/MovingMNIST/europarl-v7.fr-en.fr', encoding='utf-8').read().split('\\n')\n",
    "global n_samples_mmd, weigth_MMD, weight_loss_generator\n",
    "number_of_lines = 1000000 # number of sentences: 100k\n",
    "# n_samples_mmd = 200  #Number of samples for MMD\n",
    "BATCH_SIZE = 2500 # Number of words per batch: 7k\n",
    "weight_loss_transformer = 1\n",
    "weight_loss_generator = 100\n",
    "path_to_save_models = '/gpfs/ysm/home/ahf38/project/word_embed_align/models'\n",
    "path_to_save_plots = '/gpfs/ysm/home/ahf38/project/word_embed_align/plots'\n",
    "string_name = 'transformer_GANs_withMMD_1MSent'\n",
    "path_save = path_to_save_plots\n",
    "# weight_loss_discriminator = 0.5\n",
    "weight_loss_MMD = 10\n",
    "MMD = True\n",
    "EUCLDN = False\n",
    "n_epochs=10000\n",
    "patience=100\n",
    "# generator = GeneratorNet()\n",
    "\n",
    "\n",
    "europarl_en = islice(open('/gpfs/ysm/home/ahf38/project/word_embed_align/europarl-v7.fr-en.en', encoding='utf-8').read().split('\\n'), number_of_lines)\n",
    "europarl_fr = islice(open('/gpfs/ysm/home/ahf38/project/word_embed_align/europarl-v7.fr-en.fr', encoding='utf-8').read().split('\\n'), number_of_lines)\n",
    "# word_list = pd.read_csv('/home/antonio/Documents/MovingMNIST/word_list.csv')\n",
    "# word_list.columns = ['french', 'english']\n",
    "# for current_line in europarl_en:\n",
    "#     print (current_line)\n",
    "# print(word_list.shape)\n",
    "# print(word_list.head(500))\n",
    "\n",
    "######## Real world example #######\n",
    "if True:\n",
    "    import spacy #  Spacy is a library that has been specifically built to take sentences in various languages and split them into different tokens \n",
    "    import pandas as pd\n",
    "    from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    spacy_fr = spacy.load('fr')\n",
    "    spacy_en = spacy.load('en')\n",
    "\n",
    "    def tokenize_fr(text):\n",
    "        return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "    BOS_WORD = '<s>'\n",
    "    EOS_WORD = '</s>'\n",
    "    BLANK_WORD = \"<blank>\"\n",
    "    # SRC -> French; TGT -> English\n",
    "    SRC = data.Field(tokenize=tokenize_fr, pad_token=BLANK_WORD)\n",
    "    TGT = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, eos_token = EOS_WORD, pad_token=BLANK_WORD)\n",
    "\n",
    "    # Save the data to csv for inspection\n",
    "    raw_data = {'English' : [line for line in europarl_en], 'French': [line for line in europarl_fr]}\n",
    "    df = pd.DataFrame(raw_data, columns=[\"English\", \"French\"])\n",
    "    # remove very long sentences and sentences where translations are \n",
    "    # not of roughly equal length\n",
    "    df['eng_len'] = df['English'].str.count(' ')\n",
    "    df['fr_len'] = df['French'].str.count(' ')\n",
    "    df = df.query('fr_len < 80 & eng_len < 80')\n",
    "    df = df.query('fr_len < eng_len * 1.5 & fr_len * 1.5 > eng_len')\n",
    "    # df = df[df['English'].str.contains('football')]\n",
    "    number_of_lines = df.shape\n",
    "    # print(df['English'].head(500))\n",
    "    if EUCLDN:\n",
    "        print('Settings:\\n number_of_lines: {}\\n batch_size: {}\\n weight_loss_transformer: {}\\n weight_loss_generator: {}\\n n_epochs: {}\\n patience: {}'.format(number_of_lines, BATCH_SIZE, weight_loss_transformer, weight_loss_generator, n_epochs, patience))\n",
    "    elif MMD:\n",
    "        print('Settings:\\n number_of_lines: {}\\n batch_size: {}\\n weight_loss_transformer: {}\\n weight_loss_MMD: {}\\n n_epochs: {}\\n patience: {}'.format(number_of_lines, BATCH_SIZE, weight_loss_transformer, weight_loss_MMD, n_epochs, patience))\n",
    "    else:\n",
    "        print('Settings:\\n number_of_lines: {}\\n batch_size: {}\\n weight_loss_transformer: {}\\n n_epochs: {}\\n patience: {}'.format(number_of_lines, BATCH_SIZE, weight_loss_transformer, n_epochs, patience))\n",
    "\n",
    "    # create train and validation set \n",
    "    train, val = train_test_split(df, test_size=0.1)\n",
    "    train.to_csv(\"train.csv\", index=False)\n",
    "    val.to_csv(\"val.csv\", index=False)\n",
    "\n",
    "    # associate the text in the 'English' column with the EN_TEXT field, and 'French' with FR_TEXT\n",
    "    data_fields = [('trg', TGT), ('src', SRC)]\n",
    "    train,val = data.TabularDataset.splits(path='./', train='train.csv', validation='val.csv', format='csv', fields=data_fields)\n",
    "\n",
    "    SRC.build_vocab(train.src, val)\n",
    "    TGT.build_vocab(train.trg, val)\n",
    "    \n",
    "print('Vocabulary is built')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TGT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-889bb958b8be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpad_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTGT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<blank>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTGT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# model.src_embed.weight = model.src_embed.weight + 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TGT' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print ('Available devices {}'.format(torch.cuda.device_count()))\n",
    "\n",
    "if True:\n",
    "    pad_idx = TGT.vocab.stoi[\"<blank>\"]\n",
    "    model = make_model(len(SRC.vocab), len(TGT.vocab), N=6).to(device)\n",
    "    # model.src_embed.weight = model.src_embed.weight + 0.5\n",
    "    # model.src_embed.weight = model.src_embed.weight * 0.5\n",
    "    # with torch.no_grad():\n",
    "    #     print(model.src_embed[0].lut.weight)\n",
    "    #     # model.src_embed[0].lut.weight = model.src_embed[0].lut.weight + 0.5\n",
    "    #     # model.src_embed[0].lut.weight = model.src_embed[0].lut.weight * 0.5\n",
    "    #     # model.src_embed[0].lut.weight.masked_scatter_(torch.ones_like(model.src_embed[0].lut.weight)>0,model.src_embed[0].lut.weight+0.05)\n",
    "    #     # model.src_embed[0].lut.weight.masked_scatter_(torch.ones_like(model.src_embed[0].lut.weight)>0,model.src_embed[0].lut.weight*0.05)\n",
    "    #     # print(model.src_embed[0].lut.weight)\n",
    "    # with torch.enable_grad():\n",
    "    #     model.to(device)\n",
    "    #     print(model.src_embed[0].lut.weight)\n",
    "\n",
    "    #Save the model just with its initialization \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    torch.save(best_model_wts, os.path.join(path_to_save_models,string_name + '_epoch0.pth'))\n",
    "\n",
    "    criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=0.1).to(device)\n",
    "    # criterion.cuda()\n",
    "    train_iter = MyIterator(train, batch_size=BATCH_SIZE, device=0,\n",
    "                            repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                            batch_size_fn=batch_size_fn, train=True)\n",
    "    valid_iter = MyIterator(val, batch_size=BATCH_SIZE, device=0,\n",
    "                            repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                            batch_size_fn=batch_size_fn, train=False)\n",
    "print('Initialized model...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string_name = 'transformer_GANs_withMMD_1MSent'\n",
    "model.load_state_dict(torch.load(os.path.join(path_to_save_models,'checkpoint_' + string_name + '.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: True\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428398394/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 0 Loss: 3.9463 (loss_MMD: 1.2712, loss_trans: 2.6751) Tokens per Sec: 781.6782\n",
      "Epoch Step: 100 Loss: 4.6588 (loss_MMD: 2.1698, loss_trans: 2.4891) Tokens per Sec: 2735.7631\n",
      "Epoch Step: 200 Loss: 3.6180 (loss_MMD: 0.8894, loss_trans: 2.7286) Tokens per Sec: 2731.8367\n",
      "Epoch Step: 300 Loss: 5.5556 (loss_MMD: 3.1372, loss_trans: 2.4183) Tokens per Sec: 3107.3412\n",
      "Epoch Step: 400 Loss: 5.8826 (loss_MMD: 2.9409, loss_trans: 2.9417) Tokens per Sec: 3023.1330\n",
      "Epoch Step: 500 Loss: 4.4675 (loss_MMD: 1.6219, loss_trans: 2.8456) Tokens per Sec: 3073.9396\n",
      "Epoch Step: 600 Loss: 4.6854 (loss_MMD: 1.4618, loss_trans: 3.2236) Tokens per Sec: 3163.5795\n",
      "Epoch Step: 700 Loss: 4.9561 (loss_MMD: 1.7663, loss_trans: 3.1898) Tokens per Sec: 3048.8676\n",
      "Epoch Step: 800 Loss: 4.7286 (loss_MMD: 1.8183, loss_trans: 2.9102) Tokens per Sec: 2973.4853\n",
      "Epoch Step: 900 Loss: 5.0742 (loss_MMD: 2.4711, loss_trans: 2.6031) Tokens per Sec: 3094.8463\n",
      "Epoch Step: 1000 Loss: 9.0393 (loss_MMD: 6.5512, loss_trans: 2.4881) Tokens per Sec: 3108.0885\n",
      "Epoch Step: 1100 Loss: 4.4820 (loss_MMD: 1.3341, loss_trans: 3.1479) Tokens per Sec: 3110.5258\n",
      "Epoch Step: 1200 Loss: 5.5753 (loss_MMD: 2.9229, loss_trans: 2.6524) Tokens per Sec: 3221.5409\n",
      "Epoch Step: 1300 Loss: 4.6558 (loss_MMD: 1.5283, loss_trans: 3.1275) Tokens per Sec: 3133.1414\n",
      "Epoch Step: 1400 Loss: 5.8359 (loss_MMD: 3.0143, loss_trans: 2.8215) Tokens per Sec: 3094.4382\n",
      "Epoch Step: 1500 Loss: 9.9059 (loss_MMD: 7.9502, loss_trans: 1.9557) Tokens per Sec: 2996.1791\n",
      "Epoch Step: 1600 Loss: 5.1008 (loss_MMD: 2.2086, loss_trans: 2.8922) Tokens per Sec: 3136.0852\n",
      "Epoch Step: 1700 Loss: 4.6795 (loss_MMD: 1.6439, loss_trans: 3.0356) Tokens per Sec: 2986.3774\n",
      "Epoch Step: 1800 Loss: 6.3162 (loss_MMD: 3.6273, loss_trans: 2.6889) Tokens per Sec: 3201.3363\n",
      "Epoch Step: 1900 Loss: 5.7990 (loss_MMD: 3.0473, loss_trans: 2.7517) Tokens per Sec: 3035.7505\n",
      "Epoch Step: 2000 Loss: 5.1799 (loss_MMD: 2.4088, loss_trans: 2.7711) Tokens per Sec: 3200.5540\n",
      "Epoch Step: 2100 Loss: 6.7027 (loss_MMD: 4.0005, loss_trans: 2.7022) Tokens per Sec: 3207.9511\n",
      "Epoch Step: 2200 Loss: 4.9850 (loss_MMD: 1.9565, loss_trans: 3.0285) Tokens per Sec: 3186.6596\n",
      "Epoch Step: 2300 Loss: 5.3215 (loss_MMD: 2.4342, loss_trans: 2.8873) Tokens per Sec: 3139.5584\n",
      "Epoch Step: 2400 Loss: 6.4359 (loss_MMD: 3.4165, loss_trans: 3.0195) Tokens per Sec: 3132.2478\n",
      "Epoch Step: 2500 Loss: 6.3397 (loss_MMD: 3.4347, loss_trans: 2.9050) Tokens per Sec: 3178.4337\n"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "print('Training: {}'.format(training))\n",
    "if training:\n",
    "#     del raw_data, df\n",
    "    torch.cuda.empty_cache()\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "    # losses_discriminator_train=[]\n",
    "    losses_transformer_train=[]\n",
    "    losses_transformer_val=[]\n",
    "    if EUCLDN:\n",
    "        losses_generator_train=[]\n",
    "        losses_generator_val=[]\n",
    "        # losses_discriminator_val=[]\n",
    "    elif MMD:\n",
    "        losses_MMD_train=[]\n",
    "        losses_MMD_val=[]\n",
    "    else:\n",
    "        losses_justTransf_train=[]\n",
    "        losses_justTransf_val=[]\n",
    "\n",
    "    # losses_GAN_val=[]\n",
    "    # losses_GAN_train=[]\n",
    "    r2_landmarks_val=[]\n",
    "    # losses_MMD_train=[]\n",
    "    # losses_MMD_val=[]\n",
    "\n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=False)\n",
    "    # discriminator = DiscriminatorNet()\n",
    "    # d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "    # g_optimizer = torch.optim.Adam(model.parameters(), lr=0.0002) #At some point just set g_optimizer = model_opt\n",
    "    model_opt = NoamOpt(model.src_embed[0].d_model, 1, 2000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "    # loss_GAN = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        print('\\nStarting training...')\n",
    "        model.train()\n",
    "        # print(model) #The print works, data_gen(v,10,2) works, SimpleLossCompute works\n",
    "        # print('SRC.vocab.itos.size(0): {}'.format(len(SRC.vocab.itos)))\n",
    "        # idx_src = np.random.randint(1, len(SRC.vocab.itos), size=(1, 100))\n",
    "        # idx_tgt = np.random.randint(1, len(TGT.vocab.itos), size=(1, 100))\n",
    "        # print(SRC.vocab.itos[idx_src])\n",
    "        # print(sample(SRC.vocab.itos,3))\n",
    "        # print(len(word_list))\n",
    "        # print(word_list[0])\n",
    "        # print(train_iter)\n",
    "        # for b in train_iter:\n",
    "        #     print(b)\n",
    "        #     for j in range(1, batch.trg.size(0)):\n",
    "        #     sym = TGT.vocab.itos[batch.trg.data[j, 0]]\n",
    "        #     if sym == \"</s>\": break\n",
    "        #     print(sym, end =\" \")\n",
    "\n",
    "        # # Using GANs\n",
    "        # loss_train, loss_total_train, loss_generator_train, loss_discriminator_train, loss_transformer_train = run_epoch((rebatch(pad_idx, b) for b in train_iter), model, SimpleLossCompute(model.generator, criterion, model.src_embed[0].lut, model.tgt_embed[0].lut, SRC, TGT, discriminator, loss_GAN, english_data_target, model_opt), device=device, SRC=SRC, TGT=TGT, epoch=epoch, n_epochs=n_epochs, logger=logger)\n",
    "        # print('\\nStarting validation... ')\n",
    "        # model.eval()\n",
    "        # loss_val,loss_total_val, loss_generator_val, loss_discriminator_val, loss_transformer_val = run_epoch((rebatch(pad_idx, b) for b in valid_iter), model, SimpleLossCompute(model.generator, criterion, model.src_embed[0].lut, model.tgt_embed[0].lut, SRC, TGT, discriminator, loss_GAN, english_data_target, None), device=device, SRC=SRC, TGT=TGT, epoch=epoch, n_epochs=n_epochs, logger=logger)\n",
    "        # # \\Using GANs\n",
    "\n",
    "        # Using MSE\n",
    "        # total_loss / total_tokens, loss, total_loss_generator / total_tokens, loss_transformer\n",
    "        loss_train, loss_total_train, loss_method_train, loss_transformer_train = run_epoch((rebatch(pad_idx, b) for b in train_iter), model, SimpleLossCompute(model.generator, criterion, model.src_embed[0].lut, model.tgt_embed[0].lut, SRC, TGT, mmd, model_opt), device=device, SRC=SRC, TGT=TGT, epoch=epoch, n_epochs=n_epochs)\n",
    "        print('\\nStarting validation... ')\n",
    "        model.eval()\n",
    "        loss_val,loss_total_val, loss_method_val, loss_transformer_val = run_epoch((rebatch(pad_idx, b) for b in valid_iter), model, SimpleLossCompute(model.generator, criterion, model.src_embed[0].lut, model.tgt_embed[0].lut, SRC, TGT, mmd, None), device=device, SRC=SRC, TGT=TGT, epoch=epoch, n_epochs=n_epochs)\n",
    "        \n",
    "        if EUCLDN:\n",
    "            loss_generator_train = loss_method_train\n",
    "            loss_generator_val = loss_method_val\n",
    "        elif MMD:\n",
    "            loss_MMD_train = loss_method_train\n",
    "            loss_MMD_val = loss_method_val\n",
    "        else:\n",
    "            loss_justTransf_train = loss_method_train\n",
    "            loss_justTransf_val = loss_method_val\n",
    "        # \\Using MSE\n",
    "        # print(loss)\n",
    "\n",
    "        ### Compute error the landmarks\n",
    "        src_words_land = word_list.iloc[:,0].tolist()\n",
    "        tgt_words_land = word_list.iloc[:,1].tolist()\n",
    "        src_words_land = torch.LongTensor([[SRC.vocab.stoi[w] for w in src_words_land]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "        src_words_land = Variable(src_words_land)\n",
    "        tgt_words_land = torch.LongTensor([[TGT.vocab.stoi[w] for w in tgt_words_land]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "        tgt_words_land = Variable(tgt_words_land)\n",
    "        embed_src = model.src_embed[0].lut(src_words_land.to(device)).squeeze()\n",
    "        embed_tgt = model.tgt_embed[0].lut(tgt_words_land.to(device)).squeeze()\n",
    "\n",
    "        if epoch % 20 ==0:\n",
    "            plot_embeddings(path_save,string_name, epoch)\n",
    "\n",
    "\n",
    "        mean_r2=0\n",
    "        # print(\"embed_src.size(): {}\".format(embed_src.size()))\n",
    "        for j in range(1,embed_src.size(0)):\n",
    "            # mean_r2 += r2_score(embed_src.cpu().detach().numpy(), embed_tgt.cpu().detach().numpy())\n",
    "            mean_r2 += (np.corrcoef(embed_src[j,:].cpu().detach().numpy(), embed_tgt[j,:].cpu().detach().numpy(), rowvar=False)[0,1])**2\n",
    "        r2_landmarks = mean_r2/embed_src.size(0)\n",
    "\n",
    "        r2_landmarks_val.append(r2_landmarks)\n",
    "        train_losses.append(loss_train)\n",
    "        valid_losses.append(loss_val)\n",
    "        losses_transformer_train.append(loss_transformer_train)\n",
    "        losses_transformer_val.append(loss_transformer_val)\n",
    "        if EUCLDN:\n",
    "            losses_generator_train.append(loss_generator_train)\n",
    "            # losses_discriminator_train.append(loss_discriminator_train)\n",
    "            # losses_discriminator_val.append(loss_discriminator_val)\n",
    "            losses_generator_val.append(loss_generator_val)\n",
    "        elif MMD:\n",
    "            losses_MMD_train.append(loss_MMD_train)\n",
    "            losses_MMD_val.append(loss_MMD_val)\n",
    "        # losses_GAN_train.append(loss_GAN_train)\n",
    "        # losses_GAN_val.append(loss_GAN_val)\n",
    "        else:\n",
    "            losses_justTransf_train.append(loss_justTransf_train)\n",
    "            losses_justTransf_val.append(loss_justTransf_val)\n",
    "\n",
    "\n",
    "        train_loss = np.average(train_losses) #/ (len(dataloaders['train'].dataset))\n",
    "        valid_loss = np.average(valid_losses) #/ (len(dataloaders['val'].dataset))\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        epoch_len = len(str(n_epochs))\n",
    "\n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                 f'train_loss: {loss_train:.5f} ' +\n",
    "                 f'valid_loss: {loss_val:.5f} ' +\n",
    "                 f'landmarks_r2: {r2_landmarks:.5f}')\n",
    "        print(print_msg)\n",
    "\n",
    "         # Log batch error\n",
    "\n",
    "        # print('validation_loss: {}\\n model: {}\\n structure_net: {}'.format(valid_loss,model,structure_net))\n",
    "        # string_name = 'transformer_v6'\n",
    "        early_stopping(loss_val, model, string_name, path_to_save_models)\n",
    "#         early_stopping(loss_val, model, string_name)\n",
    "        # clear lists to track next epoch\n",
    "        # train_losses = []\n",
    "        # valid_losses = []\n",
    "\n",
    "        # print(model.src_embed[0].lut.weight)\n",
    "        if EUCLDN:\n",
    "            fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "            ax.plot(range(1,epoch+1), train_losses, '-o')\n",
    "            ax.plot(range(1,epoch+1), valid_losses, '-o')\n",
    "            ax.set(xlabel='epoch', ylabel='Loss', title='Total losses (generator+transformer)')\n",
    "            ax.legend(['train_losses','valid_losses'])\n",
    "            plt.savefig(os.path.join(path_to_save_plots,string_name+'_losses_total_'+ string_name + '.png'))\n",
    "        elif MMD:\n",
    "            fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "            ax.plot(range(1,epoch+1), train_losses, '-o')\n",
    "            ax.plot(range(1,epoch+1), valid_losses, '-o')\n",
    "            ax.set(xlabel='epoch', ylabel='Loss', title='Total losses (MMD+transformer)')\n",
    "            ax.legend(['train_losses','valid_losses'])\n",
    "            plt.savefig(os.path.join(path_to_save_plots,string_name + '_losses_total_'+ string_name + '.png'))\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "            ax.plot(range(1,epoch+1), train_losses, '-o')\n",
    "            ax.plot(range(1,epoch+1), valid_losses, '-o')\n",
    "            ax.set(xlabel='epoch', ylabel='Loss', title='Total losses (transformer)')\n",
    "            ax.legend(['train_losses','valid_losses'])\n",
    "            plt.savefig(os.path.join(path_to_save_plots,string_name + '_losses_total_'+ string_name + '.png'))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        ax.plot(range(1,epoch+1), losses_transformer_train, '-o')\n",
    "        ax.plot(range(1,epoch+1), losses_transformer_val, '-o')\n",
    "        ax.set(xlabel='epoch', ylabel='Loss', title='Transformer loss')\n",
    "        ax.legend(['losses_transformer_train','losses_transformer_val'])\n",
    "        plt.savefig(os.path.join(path_to_save_plots,string_name + '_losses_transformer_'+ string_name + '.png'))\n",
    "\n",
    "        # fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        # ax.plot(range(1,epoch+1), losses_GAN_train, '-o')\n",
    "        # ax.plot(range(1,epoch+1), losses_GAN_val, '-o')\n",
    "        # ax.set(xlabel='epoch', ylabel='Loss', title='GAN loss')\n",
    "        # ax.legend(['losses_GAN_train','losses_GAN_val'])\n",
    "        # plt.savefig('losses_GAN.png')\n",
    "\n",
    "        # fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        # ax.plot(range(1,epoch+1), losses_discriminator_train, '-o')\n",
    "        # ax.plot(range(1,epoch+1), losses_discriminator_val, '-o')\n",
    "        # ax.set(xlabel='epoch', ylabel='Loss', title='Discriminator loss')\n",
    "        # ax.legend(['losses_discriminator_train', 'losses_discriminator_val'])\n",
    "        # plt.savefig('losses_discriminator.png')\n",
    "        if EUCLDN:\n",
    "            fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "            ax.plot(range(1,epoch+1), losses_generator_train, '-o')\n",
    "            ax.plot(range(1,epoch+1), losses_generator_val, '-o')\n",
    "            ax.set(xlabel='epoch', ylabel='Loss', title='Generator loss')\n",
    "            ax.legend(['losses_generator_train', 'losses_generator_val'])\n",
    "            plt.savefig('losses_generator_'+ string_name + '.png')\n",
    "        elif MMD:\n",
    "            fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "            ax.plot(range(1,epoch+1), losses_MMD_train, '-o')\n",
    "            ax.plot(range(1,epoch+1), losses_MMD_val, '-o')\n",
    "            ax.set(xlabel='epoch', ylabel='Loss', title='MMD loss')\n",
    "            ax.legend(['losses_MMD_train','losses_MMD_val'])\n",
    "            plt.savefig('losses_MMD_'+ string_name + '.png')\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "            ax.plot(range(1,epoch+1), losses_justTransf_train, '-o')\n",
    "            ax.plot(range(1,epoch+1), losses_justTransf_val, '-o')\n",
    "            ax.set(xlabel='epoch', ylabel='Loss', title='Just Transformer')\n",
    "            ax.legend(['losses_transf_train','losses_transf_val'])\n",
    "            plt.savefig(os.path.join(path_to_save_plots,string_name + '_losses_transf_'+ string_name + '.png'))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        ax.plot(range(1,epoch+1), r2_landmarks_val, '-o')\n",
    "        ax.set(xlabel='epoch', ylabel='R^2', title='Landmarks R_2')\n",
    "        ax.legend(['r2_landmarks_val'])\n",
    "        plt.savefig(os.path.join(path_to_save_plots,string_name +'_r2_landmarks_'+ string_name + '.png'))\n",
    "\n",
    "        plt.close('all')\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        if epoch == 1:\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_wts, os.path.join(path_to_save_models,string_name + '_epoch1.pth'))\n",
    "        if epoch == n_epochs:\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_wts, os.path.join(path_to_save_models,string_name + '_lastEpoch.pth'))\n",
    "\n",
    "    #save the model\n",
    "    model.load_state_dict(torch.load(os.path.join(path_to_save_models,'checkpoint_' + string_name + '.pt')))\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    torch.save(best_model_wts, os.path.join(path_to_save_models,'best_model_' + string_name + '_transformers.pth'))\n",
    "else:\n",
    "    # model = torch.load(\"iwslt.pt\") #For some reason it is not working very well\n",
    "#     model.load_state_dict(torch.load('best_model_transformers_v4.pth'))\n",
    "    model.load_state_dict(torch.load(os.path.join(path_to_save_models,'checkpoint_' + string_name + '.pt')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_validationSet = True\n",
    "if show_validationSet:\n",
    "    for i, batch in enumerate(valid_iter):\n",
    "        print('Value of i: {}'.format(i))\n",
    "        src = batch.src.transpose(0, 1)[:1]\n",
    "        # src = batch.src.transpose(0, 1)[2]\n",
    "        # print('src: {}'.format(src))\n",
    "        # src = src.cuda()\n",
    "        src_mask = (src != SRC.vocab.stoi[\"<blank>\"]).unsqueeze(-2)\n",
    "        # src_mask = src_mask.cuda()\n",
    "        # print('src_mask: {}; src: {}'.format(src_mask.is_cuda, src.is_cuda))\n",
    "        out = greedy_decode(model.to(device), src.to(device), src_mask.to(device), max_len=60, start_symbol=TGT.vocab.stoi[\"<s>\"])\n",
    "        print(\"Translation:\", end=\"\\t\")\n",
    "        for j in range(1, out.size(1)):\n",
    "            sym = TGT.vocab.itos[out[0, j]]\n",
    "            if sym == \"</s>\": break\n",
    "            print(sym, end =\" \")\n",
    "        print()\n",
    "        print(\"Target:\", end=\"\\t\")\n",
    "        for j in range(1, batch.trg.size(0)):\n",
    "            sym = TGT.vocab.itos[batch.trg.data[j, 0]]\n",
    "            if sym == \"</s>\": break\n",
    "            print(sym, end =\" \")\n",
    "        print()\n",
    "        if i==10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translating my samples:\n",
      "Translation:\t<s> I am pleased to see that the group of the Party of European Socialists is not in favour of this . \n",
      "Translation:\t<s> The children are not , however , a word of communication . \n",
      "Translation:\t<s> It is not enough to be able to do so . \n"
     ]
    }
   ],
   "source": [
    "######## Real world example 2 ####### not working\n",
    "# model, SRC, TGT = torch.load(\"en-de-model.pt\") #not working... seems to be associated to a bug in pytorch: http://forum.opennmt.net/t/issue-loading-pretrained-models-for-machine-translation/2982\n",
    "show_mySentences = True\n",
    "if show_mySentences:\n",
    "    print(\"\\nTranslating my samples:\")\n",
    "    model.eval()\n",
    "    sent = \"Je suis si heureux de faire partie de ce groupe et vous allez tous me manque.\".split()\n",
    "    src = torch.LongTensor([[SRC.vocab.stoi[w] for w in sent]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "    src = Variable(src)\n",
    "    src_mask = (src != SRC.vocab.stoi[\"<blank>\"]).unsqueeze(-2)\n",
    "    out = greedy_decode(model.to(device), src.to(device), src_mask.to(device), max_len=60, start_symbol=TGT.vocab.stoi[\"<s>\"])\n",
    "\n",
    "    print(\"Translation:\", end=\"\\t\")\n",
    "    trans = \"<s> \"\n",
    "    for i in range(1, out.size(1)):\n",
    "        sym = TGT.vocab.itos[out[0, i]] #itos – A list of token strings indexed by their numerical identifiers.\n",
    "        if sym == \"</s>\": break\n",
    "        trans += sym + \" \"\n",
    "    print(trans)\n",
    "\n",
    "    sent = \"Les enfants courent dehors pendant que le chien aboie.\".split()\n",
    "    src = torch.LongTensor([[SRC.vocab.stoi[w] for w in sent]])\n",
    "    src = Variable(src)\n",
    "    src_mask = (src != SRC.vocab.stoi[\"<blank>\"]).unsqueeze(-2)\n",
    "    out = greedy_decode(model.to(device), src.to(device), src_mask.to(device), max_len=60, start_symbol=TGT.vocab.stoi[\"<s>\"])\n",
    "\n",
    "    print(\"Translation:\", end=\"\\t\")\n",
    "    trans = \"<s> \"\n",
    "    for i in range(1, out.size(1)):\n",
    "        sym = TGT.vocab.itos[out[0, i]]\n",
    "        if sym == \"</s>\": break\n",
    "        trans += sym + \" \"\n",
    "    print(trans)\n",
    "\n",
    "    sent = \"Il fait trop froid pour faire du vélo.\".split()\n",
    "    src = torch.LongTensor([[SRC.vocab.stoi[w] for w in sent]])\n",
    "    src = Variable(src)\n",
    "    src_mask = (src != SRC.vocab.stoi[\"<blank>\"]).unsqueeze(-2)\n",
    "    out = greedy_decode(model.to(device), src.to(device), src_mask.to(device), max_len=60, start_symbol=TGT.vocab.stoi[\"<s>\"])\n",
    "\n",
    "    print(\"Translation:\", end=\"\\t\")\n",
    "    trans = \"<s> \"\n",
    "    for i in range(1, out.size(1)):\n",
    "        sym = TGT.vocab.itos[out[0, i]]\n",
    "        if sym == \"</s>\": break\n",
    "        trans += sym + \" \"\n",
    "    print(trans)\n",
    "\n",
    "    #Print attention\n",
    "    tgt_sent = trans.split()\n",
    "    def draw(data, x, y, ax):\n",
    "        seaborn.heatmap(data, \n",
    "                        xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax)\n",
    "        \n",
    "#     for layer in range(1, 6, 2):\n",
    "#         fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "#         print(\"Encoder Layer\", layer+1)\n",
    "#         for h in range(4):\n",
    "#             draw(model.encoder.layers[layer].self_attn.attn[0, h].data.cpu(), sent, sent if h ==0 else [], ax=axs[h])\n",
    "#         plt.show()\n",
    "#         fig.suptitle('enc_layer_' + str(layer+1) , fontsize=16)\n",
    "#         plt.savefig('enc_layer_' + str(layer+1) + '.png')\n",
    "        \n",
    "#     for layer in range(1, 6, 2):\n",
    "#         fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "#         print(\"Decoder Self Layer\", layer+1)\n",
    "#         for h in range(4):\n",
    "#             draw(model.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(tgt_sent)].cpu(), \n",
    "#                 tgt_sent, tgt_sent if h ==0 else [], ax=axs[h])\n",
    "#         plt.show()\n",
    "#         fig.suptitle('dec_self_layer_' + str(layer+1) , fontsize=16)\n",
    "#         plt.savefig('dec_self_layer_' + str(layer+1) + '.png')\n",
    "#         print(\"Decoder Src Layer\", layer+1)\n",
    "#         fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "#         for h in range(4):\n",
    "#             draw(model.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(sent)].cpu(), \n",
    "#                 sent, tgt_sent if h ==0 else [], ax=axs[h])\n",
    "#         plt.show()\n",
    "#         fig.suptitle('dec_src_layer_' + str(layer+1) , fontsize=16)\n",
    "#         plt.savefig('dec_src_layer_' + str(layer+1) + '.png')\n",
    "\n",
    "######## \\Real world example 2 #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Plotting the word embedding #####\n",
    "if False: \n",
    "    for i, batch in enumerate(valid_iter):\n",
    "        print('Value of i: {}'.format(i))\n",
    "        sent = \"Je suis si heureux de faire partie de ce groupe et vous allez tous me manque.\".split()\n",
    "        src = torch.LongTensor([[SRC.vocab.stoi[w] for w in sent]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "        src = Variable(src)\n",
    "\n",
    "        print('src.size(): {}'.format(src.size()))\n",
    "        # print('src_embed.size(): {}'.format(src_embed.size()))\n",
    "        # out_emb = model.src_embed[0]\n",
    "        # print(model)\n",
    "        # print(out_emb)\n",
    "        # out_pos = model.src_embed[1]\n",
    "        # print(out_pos)\n",
    "        out_emb1 = model.src_embed[0].lut\n",
    "        print(out_emb1)\n",
    "\n",
    "        test = out_emb1(src.to(device))\n",
    "        print('test: {}'.format(test))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing word embedding (whole vocab)...\n",
      "Value of i: 0\n",
      "src: tensor([[    0,     1,     2,  ..., 30334, 30335, 30336]])\n",
      "src.size(): torch.Size([1, 30337])\n",
      "Embedding(30337, 512)\n",
      "test.size(): torch.Size([1, 30337, 512])\n",
      "test: tensor([[[-0.0065,  0.0025, -0.0068,  ..., -0.0033, -0.0004, -0.0022],\n",
      "         [ 0.0116, -0.0012,  0.0097,  ..., -0.0056,  0.0099, -0.0108],\n",
      "         [-0.0260, -0.0809, -0.1730,  ...,  0.0735,  0.0066,  0.0648],\n",
      "         ...,\n",
      "         [-0.0078, -0.0260,  0.0096,  ..., -0.0114,  0.0224, -0.0055],\n",
      "         [ 0.0219, -0.0044,  0.0106,  ..., -0.0072,  0.0422, -0.0093],\n",
      "         [ 0.0206, -0.0085,  0.0053,  ...,  0.0057, -0.0082, -0.0219]]],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "if True: \n",
    "    print('\\nShowing word embedding (whole vocab)...')\n",
    "    string_name = 'transformer_v6'\n",
    "    for i, batch in enumerate(valid_iter):\n",
    "        print('Value of i: {}'.format(i))\n",
    "        # sent = \"A veteran is a person who has had long service or experience in a particular occupation or field in the war.\".split()\n",
    "        # print('TGT.vocab: {}'.format(TGT.vocab))\n",
    "        sent = TGT.vocab.itos\n",
    "        src = torch.LongTensor([[TGT.vocab.stoi[w] for w in sent]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "        src = Variable(src)\n",
    "        print('src: {}'.format(src))\n",
    "        print('src.size(): {}'.format(src.size()))\n",
    "        # print('src_embed.size(): {}'.format(src_embed.size()))\n",
    "        # out_emb = model.src_embed[0]\n",
    "        # print(model)\n",
    "        # print(out_emb)\n",
    "        # out_pos = model.src_embed[1]\n",
    "        # print(out_pos)\n",
    "        out_emb1 = model.tgt_embed[0].lut\n",
    "        print(out_emb1)\n",
    "\n",
    "        test = out_emb1(src.to(device))\n",
    "        print('test.size(): {}'.format(test.size()))\n",
    "        print('test: {}'.format(test))\n",
    "        torch.save(test, 'tgt_embedded.pt')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### PHATE pot for the TGT (english) embedding\n",
    "# print('\\nEmbedding (from 512 to 2 or 3) with PHATE...')\n",
    "# gamma=0\n",
    "# phate_operator = phate.PHATE(n_components=2, k=5, a=20, t=10, gamma=gamma, n_jobs=-1)\n",
    "# test = test.squeeze()\n",
    "# n_samples = 2000\n",
    "# data_phate = phate_operator.fit_transform(test[:n_samples].cpu().detach().numpy())\n",
    "# torch.save(data_phate, 'data_phate_2D.pt')\n",
    "\n",
    "# ### Plot the 2D embedding (just a couple of samples)###\n",
    "# #%matplotlib notebook\n",
    "# fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "# ax.scatter(data_phate[:n_samples,0], data_phate[:n_samples,1], s=20)\n",
    "# for i in range(0,n_samples-1):\n",
    "#     ax.annotate(sent[i], (data_phate[i,0], data_phate[i,1]), fontsize=10)\n",
    "\n",
    "# # %%\n",
    "# if True: \n",
    "#     string_name = 'transformer_v6'\n",
    "#     for i, batch in enumerate(valid_iter):\n",
    "#         print('Value of i: {}'.format(i))\n",
    "#         # sent = \"A veteran is a person who has had long service or experience in a particular occupation or field in the war.\".split()\n",
    "#         # print('TGT.vocab: {}'.format(TGT.vocab))\n",
    "#         sent = SRC.vocab.itos\n",
    "#         src = torch.LongTensor([[SRC.vocab.stoi[w] for w in sent]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "#         src = Variable(src)\n",
    "#         print('src: {}'.format(src))\n",
    "#         print('src.size(): {}'.format(src.size()))\n",
    "#         # print('src_embed.size(): {}'.format(src_embed.size()))\n",
    "#         # out_emb = model.src_embed[0]\n",
    "#         # print(model)\n",
    "#         # print(out_emb)\n",
    "#         # out_pos = model.src_embed[1]\n",
    "#         # print(out_pos)\n",
    "#         out_emb1 = model.src_embed[0].lut\n",
    "#         print(out_emb1)\n",
    "\n",
    "#         test = out_emb1(src.to(device))\n",
    "#         print('test.size(): {}'.format(test.size()))\n",
    "#         print('test: {}'.format(test))\n",
    "#         torch.save(test, 'src_embedded.pt')\n",
    "#         break\n",
    "\n",
    "# # %%\n",
    "# #### PHATE pot for the TGT (english) embedding\n",
    "# print('\\nEmbedding (from 512 to 2 or 3) with PHATE...')\n",
    "# gamma=0\n",
    "# phate_operator = phate.PHATE(n_components=2, k=5, a=20, t=10, gamma=gamma, n_jobs=-1)\n",
    "# test = test.squeeze()\n",
    "# n_samples = 2000\n",
    "# data_phate = phate_operator.fit_transform(test[:n_samples].cpu().detach().numpy())\n",
    "# torch.save(data_phate, 'data_phate_src_2D.pt')\n",
    "\n",
    "# ### Plot the 2D embedding (just a couple of samples)###\n",
    "# #%matplotlib notebook\n",
    "# fig, ax = plt.subplots(figsize=(15, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "# ax.scatter(data_phate[:n_samples,0], data_phate[:n_samples,1], s=20)\n",
    "# for i in range(0,n_samples-1):\n",
    "#     ax.annotate(sent[i], (data_phate[i,0], data_phate[i,1]), fontsize=10)\n",
    "\n",
    "# # %%\n",
    "\n",
    "\n",
    "# # # # print(labels_all)\n",
    "# # fig1 = scprep.plot.scatter2d(data_phate, filename= string_name + \".png\",title=string_name, ticks=False, label_prefix=\"PHATE\")\n",
    "# # # fig2 = scprep.plot.rotate_scatter3d(data_phate, filename=string_name + \".gif\", title=string_name)\n",
    "\n",
    "\n",
    "# # phate_operator = phate.PHATE(n_components=3, k=5, a=20, t=150, gamma=gamma, n_jobs=-1)\n",
    "# # # test = test.squeeze()\n",
    "# # data_phate = phate_operator.fit_transform(test.cpu().detach().numpy())\n",
    "# # # print('data_phate shape: {}\\n'.format(data_phate.shape))\n",
    "# # torch.save(data_phate, 'data_phate_3D.pt')\n",
    "\n",
    "# # # # print(labels_all)\n",
    "# # # fig1 = scprep.plot.scatter2d(data_phate, filename= string_name + \".png\", title=string_name, ticks=False, label_prefix=\"PHATE\")\n",
    "# # fig2 = scprep.plot.rotate_scatter3d(data_phate, filename=string_name + \".gif\", title=string_name)\n",
    "\n",
    "# # plt.clf()\n",
    "# # plt.close()\n",
    "# # # gc.collect()\n",
    "\n",
    "# # del fig1, fig2\n",
    "\n",
    "# # del data_phate, phate_operator\n",
    "# # torch.cuda.empty_cache()\n",
    "\n",
    "# # # summary(model, (src, src_mask))\n",
    "\n",
    "# # %%\n",
    "# if True: \n",
    "#     string_name = 'transformer_v6'\n",
    "#     for i, batch in enumerate(valid_iter):\n",
    "#         print('Value of i: {}'.format(i))\n",
    "#         # sent = \"A veteran is a person who has had long service or experience in a particular occupation or field in the war.\".split()\n",
    "#         # print('TGT.vocab: {}'.format(TGT.vocab))\n",
    "#         sent = SRC.vocab.itos[:2000]\n",
    "#         src = torch.LongTensor([[SRC.vocab.stoi[w] for w in sent]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "#         src = Variable(src)\n",
    "#         print('src: {}'.format(src))\n",
    "#         print('src.size(): {}'.format(src.size()))\n",
    "#         # print('src_embed.size(): {}'.format(src_embed.size()))\n",
    "#         # out_emb = model.src_embed[0]\n",
    "#         # print(model)\n",
    "#         # print(out_emb)\n",
    "#         # out_pos = model.src_embed[1]\n",
    "#         # print(out_pos)\n",
    "#         out_emb1 = model.src_embed[0].lut\n",
    "#         print(out_emb1)\n",
    "\n",
    "#         test = out_emb1(src.to(device))\n",
    "#         print('test.size(): {}'.format(test.size()))\n",
    "#         print('test: {}'.format(test))\n",
    "#         torch.save(test, 'src_embedded.pt')\n",
    "        \n",
    "#         print('Value of i: {}'.format(i))\n",
    "#         # sent = \"A veteran is a person who has had long service or experience in a particular occupation or field in the war.\".split()\n",
    "#         # print('TGT.vocab: {}'.format(TGT.vocab))\n",
    "#         sent = SRC.vocab.itos[:2000]\n",
    "#         src = torch.LongTensor([[SRC.vocab.stoi[w] for w in sent]]) #stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "#         src = Variable(src)\n",
    "#         print('src: {}'.format(src))\n",
    "#         print('src.size(): {}'.format(src.size()))\n",
    "#         # print('src_embed.size(): {}'.format(src_embed.size()))\n",
    "#         # out_emb = model.src_embed[0]\n",
    "#         # print(model)\n",
    "#         # print(out_emb)\n",
    "#         # out_pos = model.src_embed[1]\n",
    "#         # print(out_pos)\n",
    "#         out_emb1 = model.src_embed[0].lut\n",
    "#         print(out_emb1)\n",
    "\n",
    "#         test = out_emb1(src.to(device))\n",
    "#         print('test.size(): {}'.format(test.size()))\n",
    "#         print('test: {}'.format(test))\n",
    "#         torch.save(test, 'src_embedded.pt')\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
